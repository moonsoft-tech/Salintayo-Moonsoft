# OpenNMT-py Training Configuration

data:
  corpus_1:
    path_src: data/train-en.txt
    path_tgt: data/train-fil.txt

vocab:
  src_vocab: data/vocab.src
  tgt_vocab: data/vocab.tgt
  vocab_size: 10000

model_dir: models/filipino_translator

Encoder:
  rnn_type: LSTM
  bidirectional: true
  layers: 1
  hidden_size: 256
  embeddings:
    embedding_size: 256

Decoder:
  rnn_type: LSTM
  layers: 1
  hidden_size: 256
  embeddings:
    embedding_size: 256

train:
  batch_size: 32
  accum_count: 1
  epochs: 50
  learning_rate: 0.001
  warmup_steps: 100
  report_every: 5
  seed: 1234
